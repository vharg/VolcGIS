{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to volcGIS Content csv/ : Root of csv files plottingApp : Bokeh function used on WOVODAT","title":"Home"},{"location":"#welcome-to-volcgis","text":"","title":"Welcome to volcGIS"},{"location":"#content","text":"csv/ : Root of csv files plottingApp : Bokeh function used on WOVODAT","title":"Content"},{"location":"basic/","text":"Getting started Basic commands Import import volcgis Defining and initializing an eruption An eruption is defined with a dictionary, e.g.: eruption = { 'name' : 'Gede-Pangrango' , 'vent' : [ - 6.787948 , 106.981215 , 2765 ], # Vent lat, lon and elevation 'extent' : [ 1.e5 , 1.e5 , 1.e5 , 1.e5 ], # extent around vent in meters, [minx maxx miny maxy] 'epsg' : 32748 } Where: name : eruption/volcano name (str) vent : geographic coordinates of the vent defined as [ lat , lon , alt ], where: lat : Latitude in decimal degrees (WGS84, negative in S hemisphere) lon : Longitude in decimal degrees (WGS84, negative in W hemisphere) alt : Vent elevation (m asl) extent : Extent of the reference region, defined as [ dxMin , dxMax , dyMin , dyMax ]: dxMin : Distance (m) from the vent in the W direction dxMax : Distance (m) from the vent in the E direction dyMin : Distance (m) from the vent in the S direction dyMax : Distance (m) from the vent in the N direction epsg : Digits of the projection to use (e.g. ) An eruption is then defined as: erup = volcgis . eruption ( eruption , res ) Where: res is the reference resolution (m) Defining and pre-processing a hazard type A hazard first requires the definition of a nameConstructor to retrieve hazard model outputs, e.g.: nameConstructor = { 'volcano' : [ 'Gede-Pangrango' ], 'VEI' : [ 'VEI3' , 'VEI4' , 'VEI5' ], 'perc' : [ 'P1' , 'P5' , 'P9' ], 'format' : [ '.tif' ] } nameConstructor is used to reconstruct the file names in a modular way, where each subcomponent is separated by an underscore _ . In this particular case, nameConstructor is designed to retrieve all these files: Gede-Pangrango_VEI3_P1.tif Gede-Pangrango_VEI3_P5.tif Gede-Pangrango_VEI3_P9.tif Gede-Pangrango_VEI4_P1.tif Gede-Pangrango_VEI4_P5.tif Gede-Pangrango_VEI4_P9.tif Gede-Pangrango_VEI5_P1.tif Gede-Pangrango_VEI5_P5.tif Gede-Pangrango_VEI5_P9.tif The hazard is the defined with another dictionary, e.g.: tephra = { 'hazard' : 'Tephra' , 'epsg' : 32748 , 'rootDir' : 'hazards/Tephra/' , 'nameConstructor' : nameConstructor , } Where: hazard : Type of hazard (arbitrary but needs to be consistent) epsg : Digits of the coordinate system of the hazard model output rootDir : Location of the hazard model output files nameConstructor : See above Preprocessing hazard files The preprocessing of hazard files is the started with: erup . prepareHazard ( tephra ) Essentially, this step: Read each file found by nameConstructor in the rootDir folder Use a virtual wrapper to reproject the hazard file to erup.epsg , clip the extent and aling pixels to the extent defined by erup.area Saves the file in volcanoes/___volcanoName/_hazard/___hazardName/ , where: ___volcanoName is erup.name ___hazardName is hazard.hazard Retrieving exposure data Reproject, crop and align extent based on erup.area / erup.epsg and saves subset in volcanoes/___volcanoName/_data/ . In all cases, a custom path to the source dataset can be specified with the named keyword argument inPth . Landscan erup . getLandscan () IMPORTANT: The strategy used to resample Landscan data is to use a nearest neighbour algorithm so as to not change pixel values and then to divide the pixel values by the ratio of original/new resolutions. However I haven't found a way to do the second step in the whole process, so this has to be done manually before analysis. For instance: # Path to Landscan file popf = 'volcanoes/ {} /_data/Landscan.tif' . format ( erup . name ) # Open file pop = rio . open ( popf ) # Read data and normalised by square of the ratio of original to resample resolutions pop_data = pop . read ( 1 ) / ( 1000 / erup . res ) ** 2 # For population count, remove noData values (i.e. -9999) pop_data [ pop_data < 1 ] = 0 # Close original raster pop . close () Landcover erup . getLandcover ()","title":"Basic commands"},{"location":"basic/#getting-started","text":"","title":"Getting started"},{"location":"basic/#basic-commands","text":"","title":"Basic commands"},{"location":"basic/#import","text":"import volcgis","title":"Import"},{"location":"basic/#defining-and-initializing-an-eruption","text":"An eruption is defined with a dictionary, e.g.: eruption = { 'name' : 'Gede-Pangrango' , 'vent' : [ - 6.787948 , 106.981215 , 2765 ], # Vent lat, lon and elevation 'extent' : [ 1.e5 , 1.e5 , 1.e5 , 1.e5 ], # extent around vent in meters, [minx maxx miny maxy] 'epsg' : 32748 } Where: name : eruption/volcano name (str) vent : geographic coordinates of the vent defined as [ lat , lon , alt ], where: lat : Latitude in decimal degrees (WGS84, negative in S hemisphere) lon : Longitude in decimal degrees (WGS84, negative in W hemisphere) alt : Vent elevation (m asl) extent : Extent of the reference region, defined as [ dxMin , dxMax , dyMin , dyMax ]: dxMin : Distance (m) from the vent in the W direction dxMax : Distance (m) from the vent in the E direction dyMin : Distance (m) from the vent in the S direction dyMax : Distance (m) from the vent in the N direction epsg : Digits of the projection to use (e.g. ) An eruption is then defined as: erup = volcgis . eruption ( eruption , res ) Where: res is the reference resolution (m)","title":"Defining and initializing an eruption"},{"location":"basic/#defining-and-pre-processing-a-hazard-type","text":"A hazard first requires the definition of a nameConstructor to retrieve hazard model outputs, e.g.: nameConstructor = { 'volcano' : [ 'Gede-Pangrango' ], 'VEI' : [ 'VEI3' , 'VEI4' , 'VEI5' ], 'perc' : [ 'P1' , 'P5' , 'P9' ], 'format' : [ '.tif' ] } nameConstructor is used to reconstruct the file names in a modular way, where each subcomponent is separated by an underscore _ . In this particular case, nameConstructor is designed to retrieve all these files: Gede-Pangrango_VEI3_P1.tif Gede-Pangrango_VEI3_P5.tif Gede-Pangrango_VEI3_P9.tif Gede-Pangrango_VEI4_P1.tif Gede-Pangrango_VEI4_P5.tif Gede-Pangrango_VEI4_P9.tif Gede-Pangrango_VEI5_P1.tif Gede-Pangrango_VEI5_P5.tif Gede-Pangrango_VEI5_P9.tif The hazard is the defined with another dictionary, e.g.: tephra = { 'hazard' : 'Tephra' , 'epsg' : 32748 , 'rootDir' : 'hazards/Tephra/' , 'nameConstructor' : nameConstructor , } Where: hazard : Type of hazard (arbitrary but needs to be consistent) epsg : Digits of the coordinate system of the hazard model output rootDir : Location of the hazard model output files nameConstructor : See above","title":"Defining and pre-processing a hazard type"},{"location":"basic/#preprocessing-hazard-files","text":"The preprocessing of hazard files is the started with: erup . prepareHazard ( tephra ) Essentially, this step: Read each file found by nameConstructor in the rootDir folder Use a virtual wrapper to reproject the hazard file to erup.epsg , clip the extent and aling pixels to the extent defined by erup.area Saves the file in volcanoes/___volcanoName/_hazard/___hazardName/ , where: ___volcanoName is erup.name ___hazardName is hazard.hazard","title":"Preprocessing hazard files"},{"location":"basic/#retrieving-exposure-data","text":"Reproject, crop and align extent based on erup.area / erup.epsg and saves subset in volcanoes/___volcanoName/_data/ . In all cases, a custom path to the source dataset can be specified with the named keyword argument inPth .","title":"Retrieving exposure data"},{"location":"basic/#landscan","text":"erup . getLandscan () IMPORTANT: The strategy used to resample Landscan data is to use a nearest neighbour algorithm so as to not change pixel values and then to divide the pixel values by the ratio of original/new resolutions. However I haven't found a way to do the second step in the whole process, so this has to be done manually before analysis. For instance: # Path to Landscan file popf = 'volcanoes/ {} /_data/Landscan.tif' . format ( erup . name ) # Open file pop = rio . open ( popf ) # Read data and normalised by square of the ratio of original to resample resolutions pop_data = pop . read ( 1 ) / ( 1000 / erup . res ) ** 2 # For population count, remove noData values (i.e. -9999) pop_data [ pop_data < 1 ] = 0 # Close original raster pop . close ()","title":"Landscan"},{"location":"basic/#landcover","text":"erup . getLandcover ()","title":"Landcover"},{"location":"changelog/","text":"Change log 2021-03-04 Moved all exposure analysis functions to volcgis.exposureAnalysis Road Exposure Updated road exposure from Josh's commit. Namely: - Removed ROAD_EXPOSURE variable and added content to EXPOSURE - Remove updateRoads and added to updateExposure getRNDS getRNDS now returns three arguments, including roadLength and RSDS roadLength is added to EXPOSURE RSDS is a pd.DataFrame that contains RSDS value for each road segment defined by Road_ID . Each column is a different hazard occurrence (i.e. hazard type, VEI, prob etc) Gekko Prepared processHazard.py for parallel processing on Gekko using Job Arrays","title":"Changelog"},{"location":"changelog/#change-log","text":"","title":"Change log"},{"location":"changelog/#2021-03-04","text":"Moved all exposure analysis functions to volcgis.exposureAnalysis","title":"2021-03-04"},{"location":"changelog/#road-exposure","text":"Updated road exposure from Josh's commit. Namely: - Removed ROAD_EXPOSURE variable and added content to EXPOSURE - Remove updateRoads and added to updateExposure","title":"Road Exposure"},{"location":"changelog/#getrnds","text":"getRNDS now returns three arguments, including roadLength and RSDS roadLength is added to EXPOSURE RSDS is a pd.DataFrame that contains RSDS value for each road segment defined by Road_ID . Each column is a different hazard occurrence (i.e. hazard type, VEI, prob etc)","title":"getRNDS"},{"location":"changelog/#gekko","text":"Prepared processHazard.py for parallel processing on Gekko using Job Arrays","title":"Gekko"},{"location":"install/","text":"Install Setup conda environment Create environment and set the channel to conda-forge : conda config --env --add channels conda-forge conda config --env --set channel_priority strict Then: conda install -c conda-forge pyarrow rioxarray rasterio geopandas bokeh contextily osmnx conda install -c conda-forge holoviews datashader panel param geoviews Additional pip packages Install these packages with pip : pip install utm pip install alive-progress Documentation To install the documentation: pip install mkdocs-material mkdocstrings livereload","title":"Install"},{"location":"install/#install","text":"","title":"Install"},{"location":"install/#setup-conda-environment","text":"Create environment and set the channel to conda-forge : conda config --env --add channels conda-forge conda config --env --set channel_priority strict Then: conda install -c conda-forge pyarrow rioxarray rasterio geopandas bokeh contextily osmnx conda install -c conda-forge holoviews datashader panel param geoviews","title":"Setup conda environment"},{"location":"install/#additional-pip-packages","text":"Install these packages with pip : pip install utm pip install alive-progress","title":"Additional pip packages"},{"location":"install/#documentation","text":"To install the documentation: pip install mkdocs-material mkdocstrings livereload","title":"Documentation"},{"location":"tips/","text":"Tips Plotting geopandas basemaps with contextily It is possible to plot basemaps to geopandas with contextily . Data needs to be in Web Mercator EPSG:3875 : import contextily as ctx fig = plt . figure ( figsize = [ 8 , 10 ]) ax = fig . add_subplot ( 1 , 1 , 1 ) ax = erup . areaG . to_crs ( 'EPSG:3857' ) . plot ( alpha = 0.5 , ax = ax ) ctx . add_basemap ( ax ) Alternatively, it is possible to re-project the basemap to EPSG:4326 : ax = erup . areaG . plot ( alpha = 0.5 ) ctx . add_basemap ( ax , crs = erup . areaG . crs . to_string ()) Join the RSDS data to the original .feather file import geopandas as gpd name = 'Taal' roadf = os . path . join ( 'volcanoes' , name , '_data/roads.feather' ) road = gpd . read_feather ( roadf ) road [ 'Road_ID' ] = road [ 'Road_ID' ] . astype ( int ) # Make sure the ID is in the same type road = road . set_index ( 'Road_ID' ) rsdsf = os . path . join ( 'volcanoes' , name , '_exposure/RSDS.csv' ) rsds = pd . read_csv ( rsdsf ) rsds = rsds . set_index ( 'Road_ID' ) ROAD = road . join ( rsds ) ROAD = ROAD . fillna ( 0 ) Starting the plotting app on Wovodat Start the bokeh plotting app in exposure.py , making it available at gee.wovodat.org/exposure conda activate ee nohup bokeh serve --allow-websocket-origin = '*' exposure.py --log-level = debug","title":"Tips"},{"location":"tips/#tips","text":"","title":"Tips"},{"location":"tips/#plotting-geopandas-basemaps-with-contextily","text":"It is possible to plot basemaps to geopandas with contextily . Data needs to be in Web Mercator EPSG:3875 : import contextily as ctx fig = plt . figure ( figsize = [ 8 , 10 ]) ax = fig . add_subplot ( 1 , 1 , 1 ) ax = erup . areaG . to_crs ( 'EPSG:3857' ) . plot ( alpha = 0.5 , ax = ax ) ctx . add_basemap ( ax ) Alternatively, it is possible to re-project the basemap to EPSG:4326 : ax = erup . areaG . plot ( alpha = 0.5 ) ctx . add_basemap ( ax , crs = erup . areaG . crs . to_string ())","title":"Plotting geopandas basemaps with contextily"},{"location":"tips/#join-the-rsds-data-to-the-original-feather-file","text":"import geopandas as gpd name = 'Taal' roadf = os . path . join ( 'volcanoes' , name , '_data/roads.feather' ) road = gpd . read_feather ( roadf ) road [ 'Road_ID' ] = road [ 'Road_ID' ] . astype ( int ) # Make sure the ID is in the same type road = road . set_index ( 'Road_ID' ) rsdsf = os . path . join ( 'volcanoes' , name , '_exposure/RSDS.csv' ) rsds = pd . read_csv ( rsdsf ) rsds = rsds . set_index ( 'Road_ID' ) ROAD = road . join ( rsds ) ROAD = ROAD . fillna ( 0 )","title":"Join the RSDS data to the original .feather file"},{"location":"tips/#starting-the-plotting-app-on-wovodat","text":"Start the bokeh plotting app in exposure.py , making it available at gee.wovodat.org/exposure conda activate ee nohup bokeh serve --allow-websocket-origin = '*' exposure.py --log-level = debug","title":"Starting the plotting app on Wovodat"},{"location":"volcGIS_eruption/","text":"volcGIS Main module to: Setup eruptions Pre-process hazard data Pre-process exposure data eruption __init__ ( self , eruption , masterRes , outPath = None ) special Sets main eruption object. Parameters: Name Type Description Default eruption dict Eruption dictionary required masterRes int Cell size (m) required outPath str Master folder for output path. If None, default is './volcanoes' None Source code in volcgis/eruption.py def __init__ ( self , eruption , masterRes , outPath = None ): ''' Sets main eruption object. Args: eruption (dict): Eruption dictionary masterRes (int): Cell size (m) outPath (str): Master folder for output path. If None, default is './volcanoes' ''' self . outPath = 'volcanoes' if outPath == None else outPath # Set default variables self . name = eruption [ 'name' ] self . res = masterRes # Set path and folders if not os . path . exists ( os . path . join ( self . outPath , self . name )): os . mkdir ( os . path . join ( self . outPath , self . name )) os . mkdir ( os . path . join ( self . outPath , self . name , '_data' )) os . mkdir ( os . path . join ( self . outPath , self . name , '_tmp' )) os . mkdir ( os . path . join ( self . outPath , self . name , '_hazard' )) os . mkdir ( os . path . join ( self . outPath , self . name , '_exposure' )) # Define projections self . EPSG = eruption [ 'epsg' ] # self.EPSG_geo = pyproj.CRS('EPSG:{}'.format(4326)) # self.EPSG_proj = pyproj.CRS('EPSG:{}'.format(self.EPSG)) self . EPSG_geo = 'epsg: {} ' . format ( 4326 ) self . EPSG_proj = 'epsg: {} ' . format ( self . EPSG ) # Convert vent into a geometry # xtmp, ytmp = pyproj.Transform.transform(self.EPSG_geo, self.EPSG_proj, eruption['vent'][0], eruption['vent'][1]) # self.vent = {'lat': eruption['vent'][0], 'lon': eruption['vent'][1], 'easting': round(xtmp), 'northing': round(ytmp), 'alt': eruption['vent'][2]} # Update Pyproj2 transformer = Transformer . from_crs ( self . EPSG_geo , self . EPSG_proj ) [ xtmp , ytmp ] = transformer . transform ( eruption [ 'vent' ][ 0 ], eruption [ 'vent' ][ 1 ]) self . vent = { 'lat' : eruption [ 'vent' ][ 0 ], 'lon' : eruption [ 'vent' ][ 1 ], 'easting' : round ( xtmp ), 'northing' : round ( ytmp ), 'alt' : eruption [ 'vent' ][ 2 ]} # Create area mask areaPl = box ( eruption [ 'extent' ][ 0 ], eruption [ 'extent' ][ 2 ], eruption [ 'extent' ][ 1 ], eruption [ 'extent' ][ 3 ]) # dxMin, dxMax, dyMin, dyMax = volcgis.makeZoneBoundaries(xtmp, ytmp, self . area = gpd . GeoDataFrame ({ 'geometry' : areaPl }, index = [ 0 ], crs = self . EPSG_proj ) # Area is now projected self . areaG = self . area . to_crs ( from_epsg ( 4326 )) # Project it # Define buffers tmp = pd . DataFrame ( self . vent , index = [ 0 ]) gdf = gpd . GeoDataFrame ( tmp , geometry = gpd . points_from_xy ( tmp . easting , tmp . northing ), crs = self . EPSG_proj ) buffer = pd . DataFrame () for iB in [ 10 , 30 , 100 ]: buffer = buffer . append ( gdf . geometry . buffer ( iB * 1e3 ) . rename ( iB )) buffer . columns = [ 'geometry' ] self . buffer = buffer # Define reference for virtual wrap on which all rasters will be aligned self . ref = {} self . ref [ 'bounds' ] = self . area . geometry [ 0 ] . bounds self . ref [ 'height' ] = len ( np . arange ( int ( self . ref [ 'bounds' ][ 1 ]), int ( self . ref [ 'bounds' ][ 3 ]), self . res )) self . ref [ 'width' ] = len ( np . arange ( int ( self . ref [ 'bounds' ][ 0 ]), int ( self . ref [ 'bounds' ][ 2 ]), self . res )) self . ref [ 'transform' ] = affine . Affine ( self . res , 0.0 , self . ref [ 'bounds' ][ 0 ], 0.0 , - self . res , self . ref [ 'bounds' ][ 3 ]) self . ref [ 'EPSG' ] = rio . crs . CRS . from_epsg ( self . EPSG ) alignRaster ( self , inPath , outPath , epsg = None , resampling = 'cubic' , scalingFactor = None ) Aligns raster to a reference grid using a virtual wrap. Use reference contained in self.ref to read a window of original file and wrap it Parameters: Name Type Description Default inPath str Path to input raster required outPath str Path to output raster required resampling str Resampling method 'cubic' scalingFactor float None Returns: Type Description image A geotif cropped, aligned and projected to self.ref['bounds'] Source code in volcgis/eruption.py def alignRaster ( self , inPath , outPath , epsg = None , resampling = 'cubic' , scalingFactor = None ): \"\"\" Aligns raster to a reference grid using a virtual wrap. Use reference contained in self.ref to read a window of original file and wrap it Args: inPath (str): Path to input raster outPath (str): Path to output raster resampling (str): Resampling method scalingFactor (float): Returns: image: A geotif cropped, aligned and projected to `self.ref['bounds']` \"\"\" # Virtual wrapper options vrt_options = { 'resampling' : Resampling . cubic , 'crs' : self . ref [ 'EPSG' ], 'transform' : self . ref [ 'transform' ], 'height' : self . ref [ 'height' ], 'width' : self . ref [ 'width' ], 'driver' : 'GTiff' } if resampling == 'nearest' : vrt_options [ 'resampling' ] = Resampling . nearest with rio . open ( inPath , 'r' ) as src : # In case no EPSG is specified (e.g. asc) if src . crs == None : # src.crs = 'EPSG:{}'.format(epsg) src . crs = rio . crs . CRS . from_epsg ( epsg ) with WarpedVRT ( src , ** vrt_options ) as vrt : rst = vrt . read ( 1 , window = from_bounds ( self . ref [ 'bounds' ][ 0 ], self . ref [ 'bounds' ][ 1 ], self . ref [ 'bounds' ][ 2 ], self . ref [ 'bounds' ][ 3 ], self . ref [ 'transform' ])) # rst = vrt.read(1, window=from_bounds(self.ref['bounds'][0], self.ref['bounds'][1], self.ref['bounds'][2], self.ref['bounds'][3], src.transform)) rio_shutil . copy ( vrt , outPath , driver = 'GTiff' , compress = 'lzw' ) # if scalingFactor is not None: # with rio.open(outPath, 'w', **profile) as src: # data = np.round(src.read(1)/(scalingFactor**2)) # src.write(data.astype(rio.int32)) getBuildingExposure ( self , inPath = None , outPath = None ) Retrieves building exposure from George's analysis for area defined by self.area. Parameters: Name Type Description Default inPath str Path to corresponding raster None !!! returns image: A geotif cropped, aligned and projected to self.ref['bounds'] Source code in volcgis/eruption.py def getBuildingExposure ( self , inPath = None , outPath = None ): \"\"\" Retrieves building exposure from George's analysis for area defined by self.area. Args: inPath (str): Path to corresponding raster Returns: image: A geotif cropped, aligned and projected to `self.ref['bounds']` \"\"\" self . alignRaster ( inPath , outPath , resampling = 'nearest' ) # if inPath is None: getLandcover ( self , inPath = None ) Retrieves Landcover data for the area defined by self.area. Resampling is set to 'nearest' for discrete data Parameters: Name Type Description Default inPath str Path to corresponding raster None !!! returns image: A geotif cropped, aligned and projected to self.ref['bounds'] Source code in volcgis/eruption.py def getLandcover ( self , inPath = None ): \"\"\" Retrieves Landcover data for the area defined by self.area. Resampling is set to 'nearest' for discrete data Args: inPath (str): Path to corresponding raster Returns: image: A geotif cropped, aligned and projected to `self.ref['bounds']` \"\"\" if inPath is None : inPath = 'DATA/LC100_2018_croped.tif' outPath = os . path . join ( self . outPath , self . name , '_data' , 'Landcover.tif' ) self . alignRaster ( inPath , outPath , resampling = 'nearest' ) getLandscan ( self , inPath = None ) Retrieves Landscan data for the area defined by self.area. Parameters: Name Type Description Default inPath str Path to corresponding raster None Returns: Type Description image A geotif cropped, aligned and projected to self.ref['bounds'] Source code in volcgis/eruption.py def getLandscan ( self , inPath = None ): \"\"\" Retrieves Landscan data for the area defined by self.area. Args: inPath (str): Path to corresponding raster Returns: image: A geotif cropped, aligned and projected to `self.ref['bounds']` \"\"\" if inPath is None : inPath = 'DATA/Landscan.tif' outPath = os . path . join ( self . outPath , self . name , '_data' , 'Landscan.tif' ) originalRes = 1000 # Landscan resolution scaling = originalRes / self . res # Scaling factor to correct population self . alignRaster ( inPath , outPath , resampling = 'nearest' , scalingFactor = scaling ) getRoadNetwork ( self , inPath = None ) Parameters: Name Type Description Default inPath str Path to the main roads dataset None Returns: Type Description roads (feather) A feather file of the roads within BBox Source code in volcgis/eruption.py def getRoadNetwork ( self , inPath = None ): \"\"\" Args: inPath (str): Path to the main roads dataset Returns: roads (feather): A feather file of the roads within BBox \"\"\" # Re-project self.areaG to pseudo mercator 3857 bbox = self . area . to_crs ( from_epsg ( 3857 )) # Get bbox for the geometry if inPath is None : inPath = 'DATA/SEA_roads_criticality.gpkg' roads = gpd . read_file ( inPath , bbox = bbox [ 'geometry' ]) # Reproject to self.EPSG roads = roads . to_crs ( crs = \"EPSG: {} \" . format ( self . EPSG )) # Save as a feather to outPath outPath = os . path . join ( self . outPath , self . name , '_data' , 'roads.feather' ) roads . to_feather ( outPath ) makeInputFileName ( self , rootDir , nameConstructor ) Create list of filenames based on nameConstructor Source code in volcgis/eruption.py def makeInputFileName ( self , rootDir , nameConstructor ): ''' Create list of filenames based on nameConstructor ''' flName = [] for p in itertools . product ( * list ( nameConstructor . values ())): fl = '_' . join ( p ) fl = rootDir + fl [: - 5 ] + fl [ - 4 :] flName . append ( fl ) return flName prepareHazard ( self , hazard ) Prepare the hazard layers Loads the files for a given hazard defined as hazard['hazard'] and from hazard['nameConstructor'] from the hazards/ folder. Parameters: Name Type Description Default hazard dict Main hazard dictionary required Returns: Type Description Geotif A geotif image Source code in volcgis/eruption.py def prepareHazard ( self , hazard ): \"\"\" Prepare the hazard layers Loads the files for a given hazard defined as hazard['hazard'] and from hazard['nameConstructor'] from the hazards/ folder. Args: hazard (dict): Main hazard dictionary Returns: Geotif: A geotif image \"\"\" print ( 'Preparing hazard: {} ' . format ( hazard [ 'hazard' ])) # Set path and folders targetDir = os . path . join ( self . outPath , self . name , '_hazard' , hazard [ 'hazard' ]) if not os . path . exists ( targetDir ): os . mkdir ( targetDir ) # Create a list of file names hazard [ 'files' ] = self . makeInputFileName ( hazard [ 'rootDir' ], hazard [ 'nameConstructor' ]) # Align files for inPath in hazard [ 'files' ]: outPath = inPath . replace ( hazard [ 'rootDir' ], '' ) outPath = outPath . replace ( '.asc' , '.tif' ) outPath = 'volcanoes/ {} /_hazard/ {} / {} ' . format ( self . name , hazard [ 'hazard' ], outPath ) print ( ' - Processing: {} ' . format ( outPath )) # If asc file, need to define projection # if inPath[-3:] == 'asc': # inPath = asc2raster(inPath, hazard # ) self . alignRaster ( inPath , outPath , epsg = hazard [ 'epsg' ]) makeZoneBoundaries ( x , y , xmin , xmax , ymin , ymax ) Calculates the boundaries in m from a central point. Useful when a boundary falls outside the limit of the zone defined by the central point. Parameters: Name Type Description Default x float Easting of the central point required y float Northing of the central point required xmin float Minimum Easting of the bounding box required xmax float Maximum Easting of the bounding box required ymin float Minimum Northing of the bounding box required ymax float Maximum Northing of the bounding box required Returns: Type Description tuple A tuple containing xmin , xmax , ymin , ymax Source code in volcgis/eruption.py def makeZoneBoundaries ( x , y , xmin , xmax , ymin , ymax ): \"\"\" Calculates the boundaries in m from a central point. Useful when a boundary falls outside the limit of the zone defined by the central point. Args: x (float): Easting of the central point y (float): Northing of the central point xmin (float): Minimum Easting of the bounding box xmax (float): Maximum Easting of the bounding box ymin (float): Minimum Northing of the bounding box ymax (float): Maximum Northing of the bounding box Returns: tuple: A tuple containing `xmin`, `xmax`, `ymin`, `ymax` \"\"\" if xmin < 0 : xmin = - 1 * ( round ( x )) + xmin else : xmin = round ( x ) - xmin xmax = xmax - x if ymin < 0 : ymin = - 1 * ( round ( x )) + ymin else : ymin = round ( x ) - ymin ymax = ymax - y return xmin , xmax , ymin , ymax parseDistanceMatrix ( pth , cX , cY , level = 0 ) Loads a geotif with xarray and returns the matrices containing data, x coordinates, y coordinates and distance from a central point. Adapted from https://xarray.pydata.org/en/v0.10.4/auto_gallery/plot_rasterio.html !!! args pth (str): Path to the geotif file cX (float): x coordinate of the centra point from which distance is calculated. Must be in the same reference coordinate as `pth` cY (float): Same as `cX` for y coordinate level (int): The depth of the data dimension to read !!! returns tuple: A tuple containing the following matrices, all of which have the same dimension: - `data (np.array)`: The data matrix - `x (np.array)`: The x-coordinate matrix - `y (np.array)`: The y-coordinate matrix - `dist (np.array)`: The matrix containing distances from `[cX, cY]` in the same unit as `pth` Source code in volcgis/eruption.py def parseDistanceMatrix ( pth , cX , cY , level = 0 ): \"\"\" Loads a geotif with xarray and returns the matrices containing data, x coordinates, y coordinates and distance from a central point. Adapted from https://xarray.pydata.org/en/v0.10.4/auto_gallery/plot_rasterio.html Args: pth (str): Path to the geotif file cX (float): x coordinate of the centra point from which distance is calculated. Must be in the same reference coordinate as `pth` cY (float): Same as `cX` for y coordinate level (int): The depth of the data dimension to read Returns: tuple: A tuple containing the following matrices, all of which have the same dimension: - `data (np.array)`: The data matrix - `x (np.array)`: The x-coordinate matrix - `y (np.array)`: The y-coordinate matrix - `dist (np.array)`: The matrix containing distances from `[cX, cY]` in the same unit as `pth` \"\"\" # Open raster with xarray and make meshgrid da = xr . open_rasterio ( pth ) data = da . data [ level ,:,:] x , y = np . meshgrid ( da [ 'x' ], da [ 'y' ]) # Compute distance to vent dist = np . sqrt ( np . power (( x - cX ), 2 ) + np . power (( y - cY ), 2 )) return data , x , y , dist","title":"Module eruption"},{"location":"volcGIS_eruption/#volcgis","text":"Main module to: Setup eruptions Pre-process hazard data Pre-process exposure data","title":"volcGIS"},{"location":"volcGIS_eruption/#volcgis.eruption.eruption","text":"","title":"eruption"},{"location":"volcGIS_eruption/#volcgis.eruption.eruption.__init__","text":"Sets main eruption object. Parameters: Name Type Description Default eruption dict Eruption dictionary required masterRes int Cell size (m) required outPath str Master folder for output path. If None, default is './volcanoes' None Source code in volcgis/eruption.py def __init__ ( self , eruption , masterRes , outPath = None ): ''' Sets main eruption object. Args: eruption (dict): Eruption dictionary masterRes (int): Cell size (m) outPath (str): Master folder for output path. If None, default is './volcanoes' ''' self . outPath = 'volcanoes' if outPath == None else outPath # Set default variables self . name = eruption [ 'name' ] self . res = masterRes # Set path and folders if not os . path . exists ( os . path . join ( self . outPath , self . name )): os . mkdir ( os . path . join ( self . outPath , self . name )) os . mkdir ( os . path . join ( self . outPath , self . name , '_data' )) os . mkdir ( os . path . join ( self . outPath , self . name , '_tmp' )) os . mkdir ( os . path . join ( self . outPath , self . name , '_hazard' )) os . mkdir ( os . path . join ( self . outPath , self . name , '_exposure' )) # Define projections self . EPSG = eruption [ 'epsg' ] # self.EPSG_geo = pyproj.CRS('EPSG:{}'.format(4326)) # self.EPSG_proj = pyproj.CRS('EPSG:{}'.format(self.EPSG)) self . EPSG_geo = 'epsg: {} ' . format ( 4326 ) self . EPSG_proj = 'epsg: {} ' . format ( self . EPSG ) # Convert vent into a geometry # xtmp, ytmp = pyproj.Transform.transform(self.EPSG_geo, self.EPSG_proj, eruption['vent'][0], eruption['vent'][1]) # self.vent = {'lat': eruption['vent'][0], 'lon': eruption['vent'][1], 'easting': round(xtmp), 'northing': round(ytmp), 'alt': eruption['vent'][2]} # Update Pyproj2 transformer = Transformer . from_crs ( self . EPSG_geo , self . EPSG_proj ) [ xtmp , ytmp ] = transformer . transform ( eruption [ 'vent' ][ 0 ], eruption [ 'vent' ][ 1 ]) self . vent = { 'lat' : eruption [ 'vent' ][ 0 ], 'lon' : eruption [ 'vent' ][ 1 ], 'easting' : round ( xtmp ), 'northing' : round ( ytmp ), 'alt' : eruption [ 'vent' ][ 2 ]} # Create area mask areaPl = box ( eruption [ 'extent' ][ 0 ], eruption [ 'extent' ][ 2 ], eruption [ 'extent' ][ 1 ], eruption [ 'extent' ][ 3 ]) # dxMin, dxMax, dyMin, dyMax = volcgis.makeZoneBoundaries(xtmp, ytmp, self . area = gpd . GeoDataFrame ({ 'geometry' : areaPl }, index = [ 0 ], crs = self . EPSG_proj ) # Area is now projected self . areaG = self . area . to_crs ( from_epsg ( 4326 )) # Project it # Define buffers tmp = pd . DataFrame ( self . vent , index = [ 0 ]) gdf = gpd . GeoDataFrame ( tmp , geometry = gpd . points_from_xy ( tmp . easting , tmp . northing ), crs = self . EPSG_proj ) buffer = pd . DataFrame () for iB in [ 10 , 30 , 100 ]: buffer = buffer . append ( gdf . geometry . buffer ( iB * 1e3 ) . rename ( iB )) buffer . columns = [ 'geometry' ] self . buffer = buffer # Define reference for virtual wrap on which all rasters will be aligned self . ref = {} self . ref [ 'bounds' ] = self . area . geometry [ 0 ] . bounds self . ref [ 'height' ] = len ( np . arange ( int ( self . ref [ 'bounds' ][ 1 ]), int ( self . ref [ 'bounds' ][ 3 ]), self . res )) self . ref [ 'width' ] = len ( np . arange ( int ( self . ref [ 'bounds' ][ 0 ]), int ( self . ref [ 'bounds' ][ 2 ]), self . res )) self . ref [ 'transform' ] = affine . Affine ( self . res , 0.0 , self . ref [ 'bounds' ][ 0 ], 0.0 , - self . res , self . ref [ 'bounds' ][ 3 ]) self . ref [ 'EPSG' ] = rio . crs . CRS . from_epsg ( self . EPSG )","title":"__init__()"},{"location":"volcGIS_eruption/#volcgis.eruption.eruption.alignRaster","text":"Aligns raster to a reference grid using a virtual wrap. Use reference contained in self.ref to read a window of original file and wrap it Parameters: Name Type Description Default inPath str Path to input raster required outPath str Path to output raster required resampling str Resampling method 'cubic' scalingFactor float None Returns: Type Description image A geotif cropped, aligned and projected to self.ref['bounds'] Source code in volcgis/eruption.py def alignRaster ( self , inPath , outPath , epsg = None , resampling = 'cubic' , scalingFactor = None ): \"\"\" Aligns raster to a reference grid using a virtual wrap. Use reference contained in self.ref to read a window of original file and wrap it Args: inPath (str): Path to input raster outPath (str): Path to output raster resampling (str): Resampling method scalingFactor (float): Returns: image: A geotif cropped, aligned and projected to `self.ref['bounds']` \"\"\" # Virtual wrapper options vrt_options = { 'resampling' : Resampling . cubic , 'crs' : self . ref [ 'EPSG' ], 'transform' : self . ref [ 'transform' ], 'height' : self . ref [ 'height' ], 'width' : self . ref [ 'width' ], 'driver' : 'GTiff' } if resampling == 'nearest' : vrt_options [ 'resampling' ] = Resampling . nearest with rio . open ( inPath , 'r' ) as src : # In case no EPSG is specified (e.g. asc) if src . crs == None : # src.crs = 'EPSG:{}'.format(epsg) src . crs = rio . crs . CRS . from_epsg ( epsg ) with WarpedVRT ( src , ** vrt_options ) as vrt : rst = vrt . read ( 1 , window = from_bounds ( self . ref [ 'bounds' ][ 0 ], self . ref [ 'bounds' ][ 1 ], self . ref [ 'bounds' ][ 2 ], self . ref [ 'bounds' ][ 3 ], self . ref [ 'transform' ])) # rst = vrt.read(1, window=from_bounds(self.ref['bounds'][0], self.ref['bounds'][1], self.ref['bounds'][2], self.ref['bounds'][3], src.transform)) rio_shutil . copy ( vrt , outPath , driver = 'GTiff' , compress = 'lzw' ) # if scalingFactor is not None: # with rio.open(outPath, 'w', **profile) as src: # data = np.round(src.read(1)/(scalingFactor**2)) # src.write(data.astype(rio.int32))","title":"alignRaster()"},{"location":"volcGIS_eruption/#volcgis.eruption.eruption.getBuildingExposure","text":"Retrieves building exposure from George's analysis for area defined by self.area. Parameters: Name Type Description Default inPath str Path to corresponding raster None !!! returns image: A geotif cropped, aligned and projected to self.ref['bounds'] Source code in volcgis/eruption.py def getBuildingExposure ( self , inPath = None , outPath = None ): \"\"\" Retrieves building exposure from George's analysis for area defined by self.area. Args: inPath (str): Path to corresponding raster Returns: image: A geotif cropped, aligned and projected to `self.ref['bounds']` \"\"\" self . alignRaster ( inPath , outPath , resampling = 'nearest' ) # if inPath is None:","title":"getBuildingExposure()"},{"location":"volcGIS_eruption/#volcgis.eruption.eruption.getLandcover","text":"Retrieves Landcover data for the area defined by self.area. Resampling is set to 'nearest' for discrete data Parameters: Name Type Description Default inPath str Path to corresponding raster None !!! returns image: A geotif cropped, aligned and projected to self.ref['bounds'] Source code in volcgis/eruption.py def getLandcover ( self , inPath = None ): \"\"\" Retrieves Landcover data for the area defined by self.area. Resampling is set to 'nearest' for discrete data Args: inPath (str): Path to corresponding raster Returns: image: A geotif cropped, aligned and projected to `self.ref['bounds']` \"\"\" if inPath is None : inPath = 'DATA/LC100_2018_croped.tif' outPath = os . path . join ( self . outPath , self . name , '_data' , 'Landcover.tif' ) self . alignRaster ( inPath , outPath , resampling = 'nearest' )","title":"getLandcover()"},{"location":"volcGIS_eruption/#volcgis.eruption.eruption.getLandscan","text":"Retrieves Landscan data for the area defined by self.area. Parameters: Name Type Description Default inPath str Path to corresponding raster None Returns: Type Description image A geotif cropped, aligned and projected to self.ref['bounds'] Source code in volcgis/eruption.py def getLandscan ( self , inPath = None ): \"\"\" Retrieves Landscan data for the area defined by self.area. Args: inPath (str): Path to corresponding raster Returns: image: A geotif cropped, aligned and projected to `self.ref['bounds']` \"\"\" if inPath is None : inPath = 'DATA/Landscan.tif' outPath = os . path . join ( self . outPath , self . name , '_data' , 'Landscan.tif' ) originalRes = 1000 # Landscan resolution scaling = originalRes / self . res # Scaling factor to correct population self . alignRaster ( inPath , outPath , resampling = 'nearest' , scalingFactor = scaling )","title":"getLandscan()"},{"location":"volcGIS_eruption/#volcgis.eruption.eruption.getRoadNetwork","text":"Parameters: Name Type Description Default inPath str Path to the main roads dataset None Returns: Type Description roads (feather) A feather file of the roads within BBox Source code in volcgis/eruption.py def getRoadNetwork ( self , inPath = None ): \"\"\" Args: inPath (str): Path to the main roads dataset Returns: roads (feather): A feather file of the roads within BBox \"\"\" # Re-project self.areaG to pseudo mercator 3857 bbox = self . area . to_crs ( from_epsg ( 3857 )) # Get bbox for the geometry if inPath is None : inPath = 'DATA/SEA_roads_criticality.gpkg' roads = gpd . read_file ( inPath , bbox = bbox [ 'geometry' ]) # Reproject to self.EPSG roads = roads . to_crs ( crs = \"EPSG: {} \" . format ( self . EPSG )) # Save as a feather to outPath outPath = os . path . join ( self . outPath , self . name , '_data' , 'roads.feather' ) roads . to_feather ( outPath )","title":"getRoadNetwork()"},{"location":"volcGIS_eruption/#volcgis.eruption.eruption.makeInputFileName","text":"Create list of filenames based on nameConstructor Source code in volcgis/eruption.py def makeInputFileName ( self , rootDir , nameConstructor ): ''' Create list of filenames based on nameConstructor ''' flName = [] for p in itertools . product ( * list ( nameConstructor . values ())): fl = '_' . join ( p ) fl = rootDir + fl [: - 5 ] + fl [ - 4 :] flName . append ( fl ) return flName","title":"makeInputFileName()"},{"location":"volcGIS_eruption/#volcgis.eruption.eruption.prepareHazard","text":"Prepare the hazard layers Loads the files for a given hazard defined as hazard['hazard'] and from hazard['nameConstructor'] from the hazards/ folder. Parameters: Name Type Description Default hazard dict Main hazard dictionary required Returns: Type Description Geotif A geotif image Source code in volcgis/eruption.py def prepareHazard ( self , hazard ): \"\"\" Prepare the hazard layers Loads the files for a given hazard defined as hazard['hazard'] and from hazard['nameConstructor'] from the hazards/ folder. Args: hazard (dict): Main hazard dictionary Returns: Geotif: A geotif image \"\"\" print ( 'Preparing hazard: {} ' . format ( hazard [ 'hazard' ])) # Set path and folders targetDir = os . path . join ( self . outPath , self . name , '_hazard' , hazard [ 'hazard' ]) if not os . path . exists ( targetDir ): os . mkdir ( targetDir ) # Create a list of file names hazard [ 'files' ] = self . makeInputFileName ( hazard [ 'rootDir' ], hazard [ 'nameConstructor' ]) # Align files for inPath in hazard [ 'files' ]: outPath = inPath . replace ( hazard [ 'rootDir' ], '' ) outPath = outPath . replace ( '.asc' , '.tif' ) outPath = 'volcanoes/ {} /_hazard/ {} / {} ' . format ( self . name , hazard [ 'hazard' ], outPath ) print ( ' - Processing: {} ' . format ( outPath )) # If asc file, need to define projection # if inPath[-3:] == 'asc': # inPath = asc2raster(inPath, hazard # ) self . alignRaster ( inPath , outPath , epsg = hazard [ 'epsg' ])","title":"prepareHazard()"},{"location":"volcGIS_eruption/#volcgis.eruption.makeZoneBoundaries","text":"Calculates the boundaries in m from a central point. Useful when a boundary falls outside the limit of the zone defined by the central point. Parameters: Name Type Description Default x float Easting of the central point required y float Northing of the central point required xmin float Minimum Easting of the bounding box required xmax float Maximum Easting of the bounding box required ymin float Minimum Northing of the bounding box required ymax float Maximum Northing of the bounding box required Returns: Type Description tuple A tuple containing xmin , xmax , ymin , ymax Source code in volcgis/eruption.py def makeZoneBoundaries ( x , y , xmin , xmax , ymin , ymax ): \"\"\" Calculates the boundaries in m from a central point. Useful when a boundary falls outside the limit of the zone defined by the central point. Args: x (float): Easting of the central point y (float): Northing of the central point xmin (float): Minimum Easting of the bounding box xmax (float): Maximum Easting of the bounding box ymin (float): Minimum Northing of the bounding box ymax (float): Maximum Northing of the bounding box Returns: tuple: A tuple containing `xmin`, `xmax`, `ymin`, `ymax` \"\"\" if xmin < 0 : xmin = - 1 * ( round ( x )) + xmin else : xmin = round ( x ) - xmin xmax = xmax - x if ymin < 0 : ymin = - 1 * ( round ( x )) + ymin else : ymin = round ( x ) - ymin ymax = ymax - y return xmin , xmax , ymin , ymax","title":"makeZoneBoundaries()"},{"location":"volcGIS_eruption/#volcgis.eruption.parseDistanceMatrix","text":"Loads a geotif with xarray and returns the matrices containing data, x coordinates, y coordinates and distance from a central point. Adapted from https://xarray.pydata.org/en/v0.10.4/auto_gallery/plot_rasterio.html !!! args pth (str): Path to the geotif file cX (float): x coordinate of the centra point from which distance is calculated. Must be in the same reference coordinate as `pth` cY (float): Same as `cX` for y coordinate level (int): The depth of the data dimension to read !!! returns tuple: A tuple containing the following matrices, all of which have the same dimension: - `data (np.array)`: The data matrix - `x (np.array)`: The x-coordinate matrix - `y (np.array)`: The y-coordinate matrix - `dist (np.array)`: The matrix containing distances from `[cX, cY]` in the same unit as `pth` Source code in volcgis/eruption.py def parseDistanceMatrix ( pth , cX , cY , level = 0 ): \"\"\" Loads a geotif with xarray and returns the matrices containing data, x coordinates, y coordinates and distance from a central point. Adapted from https://xarray.pydata.org/en/v0.10.4/auto_gallery/plot_rasterio.html Args: pth (str): Path to the geotif file cX (float): x coordinate of the centra point from which distance is calculated. Must be in the same reference coordinate as `pth` cY (float): Same as `cX` for y coordinate level (int): The depth of the data dimension to read Returns: tuple: A tuple containing the following matrices, all of which have the same dimension: - `data (np.array)`: The data matrix - `x (np.array)`: The x-coordinate matrix - `y (np.array)`: The y-coordinate matrix - `dist (np.array)`: The matrix containing distances from `[cX, cY]` in the same unit as `pth` \"\"\" # Open raster with xarray and make meshgrid da = xr . open_rasterio ( pth ) data = da . data [ level ,:,:] x , y = np . meshgrid ( da [ 'x' ], da [ 'y' ]) # Compute distance to vent dist = np . sqrt ( np . power (( x - cX ), 2 ) + np . power (( y - cY ), 2 )) return data , x , y , dist","title":"parseDistanceMatrix()"},{"location":"volcGIS_exposureAnalysis/","text":"volcGIS.exposureAnalysis The module volcgis.exposureAnalysis contains most functions to estimate exposure and impact. getBufferExposure ( buffer , fl ) Get exposure Source code in volcgis/exposureAnalysis.py def getBufferExposure ( buffer , fl ): \"\"\" Get exposure \"\"\" # Get hazard index idx = haz_data >= val # Population popTmp = np . sum ( pop_data [ idx ]) # Landcover / crops km2 idx = ( haz_data >= val ) & ( LC_data == 40 ) cropsTmp = np . sum ( idx ) * res ** 2 / 1e6 # Landcover / urban km2 idx = ( haz_data >= val ) & ( LC_data == 50 ) urbanTmp = np . sum ( idx ) * res ** 2 / 1e6 return round ( popTmp , 0 ), round ( cropsTmp , 0 ), round ( urbanTmp , 0 ) getBuildingImpact ( haz_data , build_data , vuln , outPath , flName , erup , profile ) Physical impact on buildings from tephra fallout Parameters: Name Type Description Default vuln pd.Series CSV file containing the parameters of the fragility curves. Must contain the following fields: load_mean, load_disp, tot_rep_cost required outPth str Main output directory required flName str String appended to the raster names. If None , no raster is written required erup str Volcano name required profile dict Rasterio reference profile for writing output required Source code in volcgis/exposureAnalysis.py def getBuildingImpact ( haz_data , build_data , vuln , outPath , flName , erup , profile ): \"\"\" Physical impact on buildings from tephra fallout Args: vuln (pd.Series): CSV file containing the parameters of the fragility curves. Must contain the following fields: load_mean, load_disp, tot_rep_cost outPth (str): Main output directory flName (str): String appended to the raster names. If ``None``, no raster is written erup (str): Volcano name profile (dict): Rasterio reference profile for writing output \"\"\" # Import damage state dr2ds = pd . read_csv ( 'csv/ratio_to_damage.csv' ) dr2ds . columns = [ 'DS' , 'DS_level ' , 'cdv ' , 'dr_range' , 'dr_lwr' , 'dr_upr' ] # Get the damage ratio f_damageRatio = lambda mn , dsp , load : scipy . stats . norm ( loc = math . log ( mn ), scale = dsp ) . cdf ( np . log ( load )) haz_data [ haz_data < .1 ] = np . nan damageRatio = f_damageRatio ( vuln [ 'load_mean' ], vuln [ 'load_disp' ], haz_data ) # Multiply the total by the damage ratio and by the number of buildings that were exposed to a specific tephra fall load loss = damageRatio * vuln [ 'tot_rep_cost' ] * build_data loss [ loss < 0 ] = 0 # Just make sure there are no negative values # Convert damage ratio to damage state damageState = np . zeros ( damageRatio . shape ) for i in range ( 1 , 6 ): damageState [ damageRatio >= dr2ds . iloc [ i ][ 'dr_upr' ]] = i ## Write the rasters if flName is not None : # Write damage ratio as raster with rio . open ( os . path . join ( outPath , erup , '_exposure/damageRatio_ {} ' . format ( flName )), 'w' , ** profile ) as dst : dst . write ( damageRatio , 1 ) # Write loss as raster with rio . open ( os . path . join ( outPath , erup , '_exposure/loss_ {} ' . format ( flName )), 'w' , ** profile ) as dst : dst . write ( loss , 1 ) ## Write the tiffs # Damage ratio table damageRatioR = np . round ( damageRatio , 1 ) DR = np . round ( np . linspace ( 0 , 1 , 11 ), 2 ) storDR = { 'damageRatio' : DR , 'nBuildings' : np . zeros ( DR . shape ), 'loss' : np . zeros ( DR . shape ), } storDR = pd . DataFrame ( storDR ) storDR = storDR . set_index ( 'damageRatio' ) for iR in DR : idx = damageRatioR == iR storDR . loc [ iR , 'nBuildings' ] = np . sum ( build_data [ idx ]) storDR . loc [ iR , 'loss' ] = np . sum ( loss [ idx ]) # Damage state table DS = np . linspace ( 0 , 5 , 6 ) # DS = [int(d) for d in DS] storDS = { 'damageState' : DS , 'nBuildings' : np . zeros ( DS . shape ), 'loss' : np . zeros ( DS . shape ), } storDS = pd . DataFrame ( storDS ) storDS = storDS . set_index ( 'damageState' ) for iR in DS : idx = damageState == iR storDS . loc [ iR , 'nBuildings' ] = np . sum ( build_data [ idx ]) storDS . loc [ iR , 'loss' ] = np . sum ( loss [ idx ]) return storDR , storDS getExposure ( haz_data , pop_data , LC_data , res , val ) Compute exposure from masking exposure datasets with hazard data. For the landcover data, using CGLS so urban==50 and crops==40 Parameters: Name Type Description Default haz_data np.array Hazard data required pop_data np.array Population density data required LC_data np.array Landcover data required res int Raster resolution required val float Hazard value to mask required Returns: Type Description tuple A tuple containing: population (float) : Cumulative number of people within hazard value crops (float) : Total exposed crop area (km^2) urban (float) : Total exposed urban area (km^2) Source code in volcgis/exposureAnalysis.py def getExposure ( haz_data , pop_data , LC_data , res , val ): \"\"\" Compute exposure from masking exposure datasets with hazard data. For the landcover data, using `CGLS` so `urban==50` and `crops==40` Args: haz_data (np.array): Hazard data pop_data (np.array): Population density data LC_data (np.array): Landcover data res (int): Raster resolution val (float): Hazard value to mask Returns: tuple: A tuple containing: - `population (float)`: Cumulative number of people within hazard value - `crops (float)`: Total exposed crop area (km^2) - `urban (float)`: Total exposed urban area (km^2) \"\"\" # Get hazard index idx = haz_data >= val # Population popTmp = np . sum ( pop_data [ idx ]) # Landcover / crops km2 idx = ( haz_data >= val ) & ( LC_data == 40 ) cropsTmp = np . sum ( idx ) * res ** 2 / 1e6 # Landcover / urban km2 idx = ( haz_data >= val ) & ( LC_data == 50 ) urbanTmp = np . sum ( idx ) * res ** 2 / 1e6 return round ( popTmp , 0 ), round ( cropsTmp , 0 ), round ( urbanTmp , 0 ) getFeatures ( gdf ) Function to parse features from GeoDataFrame in such a manner that rasterio wants them Source code in volcgis/exposureAnalysis.py def getFeatures ( gdf ): \"\"\"Function to parse features from GeoDataFrame in such a manner that rasterio wants them\"\"\" return [ json . loads ( gdf . to_json ())[ 'features' ][ 0 ][ 'geometry' ]] getRNDS ( hazardPath , dictMap , road , epsg , intensity ) Parameters: Name Type Description Default hazardPath str Path to hazard file required dictMap dict required road gpd required epsg int Digits of the epsg code required intensity bool Defines if hazard file contains probabilities (False) or hazard intensity metrics (True) required Returns: Type Description tuple A tuple containing: - rnds (float, dict): RNDN value, either as a float (if intensity==True) or a dictionary (if intensity==False) - roadLength (pd.DataFrame): Length of each road type defined in the `highway` column of the road variable. Each row is a road type, each column is a single value defined in dictMap - rsds (pd.DataFrame): RSDS value of each road segment defined by `Road_ID` Source code in volcgis/exposureAnalysis.py def getRNDS ( hazardPath , dictMap , road , epsg , intensity ): \"\"\" Arguments: hazardPath (str): Path to hazard file dictMap (dict): road (gpd): epsg (int): Digits of the epsg code intensity (bool): Defines if hazard file contains probabilities (False) or hazard intensity metrics (True) Returns: tuple: A tuple containing: - rnds (float, dict): RNDN value, either as a float (if intensity==True) or a dictionary (if intensity==False) - roadLength (pd.DataFrame): Length of each road type defined in the `highway` column of the road variable. Each row is a road type, each column is a single value defined in dictMap - rsds (pd.DataFrame): RSDS value of each road segment defined by `Road_ID` \"\"\" # Make sure dicMap is ordered in decreasing keys dictMap = dict ( sorted ( dictMap . items (), key = lambda item : item [ 0 ], reverse = True )) # Convert it to a tuple so we can iterate back and forth inpVal = [( k , v ) for k , v in dictMap . items ()] # Output rnds = {} # Set id road = road . set_index ( 'Road_ID' ) # Output dataframe that will contain the length roadLength = pd . DataFrame ( columns = dictMap . keys (), index = road . highway . unique ()) with rio . open ( hazardPath ) as src : #Read image image = src . read () # Loop through dictMap, which returns threshold and impact score # for threshold, score in dictMap.items(): for i in range ( 0 , len ( inpVal )): # Get threshold and score threshold = inpVal [ i ][ 0 ] #threshold_str = str(threshold) score = inpVal [ i ][ 1 ] # Create a mask mask = image >= threshold mask = mask . astype ( 'uint8' ) # In case the hazard type is tephra and the loop is not pointing to the innermost zone, # then we substract the previous mask if i > 0 and intensity : maskP = image >= inpVal [ i - 1 ][ 0 ] maskP = maskP . astype ( 'uint8' ) mask = mask - maskP shapes = rio . features . shapes ( mask , transform = src . transform ) # Extract geometry from shapes geometry = [] for shapedict , value in shapes : if value == 1 : geometry . append ( shape ( shapedict )) # Create gdf for clipping gdf = gpd . GeoDataFrame ( { 'geometry' : geometry }, crs = \"EPSG: {} \" . format ( epsg )) # In case the mask for the given threshold is empty if gdf . size == 0 : rnds [ threshold ] = 0 else : # Create GeoDataFrame clipped_road = gpd . clip ( road , gdf ) clipped_road [ 'impact_score' ] = score clipped_road [ 'RSDS_ {} ' . format ( threshold )] = clipped_road [ 'Criticality score' ] * clipped_road [ 'LoR_score' ] * clipped_road [ 'impact_score' ] rnds [ threshold ] = clipped_road [ 'RSDS_ {} ' . format ( threshold )] . sum () # Calculate total road length per `highway` type and append to the storage df roadLengthTmp = clipped_road . groupby ( 'highway' ) . sum ()[[ 'Length_m' ]] roadLength . loc [ roadLengthTmp . index , threshold ] = roadLengthTmp . loc [ roadLengthTmp . index , 'Length_m' ] # Append the RSDS to the full road network road = road . join ( clipped_road [[ 'RSDS_ {} ' . format ( threshold )]]) # Sum all values if intensity == True : rnds = sum ( rnds . values ()) else : pass # Remove the highway types that don't have any data roadLength = roadLength . dropna ( how = 'all' ) # Filter the RSDS columns to save them with the `Road_ID` rsds = road . filter ( regex = ( \"RSDS*\" )) rsds = rsds . dropna ( how = 'all' ) return rnds , roadLength , rsds updateBuildingExposure ( damageRatio , damageState , volcano , VEI , prob , typ , DR , DS ) Update building exposure and impact to tephra accumulation Parameters: Name Type Description Default damageRatio pd.DataFrame Master damage ratio dataframe required damageState pd.DataFrame Master damage state dataframe required volcano str Volcano name required VEI str VEI required prob str Probability required typ str Building type required DR pd.DataFrame Damage ratio dataframe for a given volcano/vei/prob required DS pd.DataFrame Damage state dataframe for a given volcano/vei/prob required Source code in volcgis/exposureAnalysis.py def updateBuildingExposure ( damageRatio , damageState , volcano , VEI , prob , typ , DR , DS ): \"\"\" Update building exposure and impact to tephra accumulation Arguments: damageRatio (pd.DataFrame): Master damage ratio dataframe damageState (pd.DataFrame): Master damage state dataframe volcano (str): Volcano name VEI (str): VEI prob (str): Probability typ (str): Building type DR (pd.DataFrame): Damage ratio dataframe for a given volcano/vei/prob DS (pd.DataFrame): Damage state dataframe for a given volcano/vei/prob \"\"\" DR [ 'volcano' ] = volcano DR [ 'VEI' ] = VEI DR [ 'prob' ] = prob DR [ 'type' ] = typ DS [ 'volcano' ] = volcano DS [ 'VEI' ] = VEI DS [ 'prob' ] = prob DS [ 'type' ] = typ return damageRatio . append ( DR ), damageState . append ( DS ) updateExposure ( EXPOSURE , volcano , hazard , VEI , prob , intensity , buffer , volume , pop , crops , urban , RNDS , buildingsLoss ) Updates main exposure dataframe. Buildings loss is in millions. Parameters: Name Type Description Default EXPOSURE pd.DataFrame Main dataframe to update required volcano str Volcano name required hazard str Hazard name required VEI float VEI required prob float Probability required intensity float Hazard intensity required buffer float required volume float required pop float required crops float required urban float required RNDS float required buildingsLoss float required Returns: Type Description pd.DataFrame Updated data frame Source code in volcgis/exposureAnalysis.py def updateExposure ( EXPOSURE , volcano , hazard , VEI , prob , intensity , buffer , volume , pop , crops , urban , RNDS , buildingsLoss ): \"\"\" Updates main exposure dataframe. Buildings loss is in millions. Args: EXPOSURE (pd.DataFrame): Main dataframe to update volcano (str): Volcano name hazard (str): Hazard name VEI (float): VEI prob (float): Probability intensity (float): Hazard intensity buffer (float): volume (float): pop (float): crops (float): urban (float): RNDS (float): buildingsLoss (float): Returns: pd.DataFrame: Updated data frame \"\"\" expTmp = { 'volcano' : [ volcano ], 'hazard' : [ hazard ], 'VEI' : [ VEI ], 'prob' : [ prob ], 'mass' : [ intensity ], 'buffer' : [ buffer ], 'volume' : [ volume ], 'pop_count' : [ pop ], 'area_crops' : [ crops ], 'area_urban' : [ urban ], 'RNDS' : [ RNDS ], 'buildingsLoss' :[ buildingsLoss ], } expTmp = pd . DataFrame ( expTmp ) # If roadLength is defined, then add the columns with length_ appended to the column name # if roadLength is not None: # for iRoad in range(roadLength.shape[0]): # name = roadLength.iloc[iRoad].name # expTmp['length_' + name] = roadLength.loc[name].values[0] return EXPOSURE . append ( expTmp ) updateRoadExposure ( roadExposure , volcano , hazard , VEI , prob , intensity , buffer , volume , roadLength ) Updates road exposure. Length is in km Source code in volcgis/exposureAnalysis.py def updateRoadExposure ( roadExposure , volcano , hazard , VEI , prob , intensity , buffer , volume , roadLength ): \"\"\" Updates road exposure. Length is in km \"\"\" expTmp = { 'volcano' : [ volcano ], 'hazard' : [ hazard ], 'VEI' : [ VEI ], 'prob' : [ prob ], 'mass' : [ intensity ], 'buffer' : [ buffer ], 'volume' : [ volume ], } expTmp = pd . DataFrame ( expTmp ) for iRoad in range ( roadLength . shape [ 0 ]): name = roadLength . iloc [ iRoad ] . name expTmp [ 'length_' + name ] = round ( roadLength . loc [ name ] . values [ 0 ] / 1e3 , 2 ) return roadExposure . append ( expTmp ) updateRSDS ( RSDS , rsds ) Update the rsds for a given eruption. It assumes that all the variables (i.e. hazard type, VEI, probs etc) are contained in the column name. Just thinking along mapping them on a GIS, it will make more sense to have all the data in one single file so only one join is required. Parameters: Name Type Description Default RSDS pd.DataFrame Main storage, row is Road_ID , column is a given hazard occurrence required rsds pd.DataFrame RSDS for one hazard occurrence, row is Road_ID required Returns: Type Description pd.DataFrame Updated RSDS dataframe Source code in volcgis/exposureAnalysis.py def updateRSDS ( RSDS , rsds ): \"\"\" Update the rsds for a given eruption. It assumes that all the variables (i.e. hazard type, VEI, probs etc) are contained in the column name. Just thinking along mapping them on a GIS, it will make more sense to have all the data in one single file so only one join is required. Args: RSDS (pd.DataFrame): Main storage, row is `Road_ID`, column is a given hazard occurrence rsds (pd.DataFrame): RSDS for one hazard occurrence, row is `Road_ID` Returns: pd.DataFrame: Updated RSDS dataframe \"\"\" rsds_tmp = rsds . copy () # If first call of updateRSDS if RSDS . shape [ 0 ] == 0 : RSDS = rsds_tmp else : RSDS = RSDS . join ( rsds_tmp ) return RSDS","title":"Module exposureAnalysis"},{"location":"volcGIS_exposureAnalysis/#volcgisexposureanalysis","text":"The module volcgis.exposureAnalysis contains most functions to estimate exposure and impact.","title":"volcGIS.exposureAnalysis"},{"location":"volcGIS_exposureAnalysis/#volcgis.exposureAnalysis.getBufferExposure","text":"Get exposure Source code in volcgis/exposureAnalysis.py def getBufferExposure ( buffer , fl ): \"\"\" Get exposure \"\"\" # Get hazard index idx = haz_data >= val # Population popTmp = np . sum ( pop_data [ idx ]) # Landcover / crops km2 idx = ( haz_data >= val ) & ( LC_data == 40 ) cropsTmp = np . sum ( idx ) * res ** 2 / 1e6 # Landcover / urban km2 idx = ( haz_data >= val ) & ( LC_data == 50 ) urbanTmp = np . sum ( idx ) * res ** 2 / 1e6 return round ( popTmp , 0 ), round ( cropsTmp , 0 ), round ( urbanTmp , 0 )","title":"getBufferExposure()"},{"location":"volcGIS_exposureAnalysis/#volcgis.exposureAnalysis.getBuildingImpact","text":"Physical impact on buildings from tephra fallout Parameters: Name Type Description Default vuln pd.Series CSV file containing the parameters of the fragility curves. Must contain the following fields: load_mean, load_disp, tot_rep_cost required outPth str Main output directory required flName str String appended to the raster names. If None , no raster is written required erup str Volcano name required profile dict Rasterio reference profile for writing output required Source code in volcgis/exposureAnalysis.py def getBuildingImpact ( haz_data , build_data , vuln , outPath , flName , erup , profile ): \"\"\" Physical impact on buildings from tephra fallout Args: vuln (pd.Series): CSV file containing the parameters of the fragility curves. Must contain the following fields: load_mean, load_disp, tot_rep_cost outPth (str): Main output directory flName (str): String appended to the raster names. If ``None``, no raster is written erup (str): Volcano name profile (dict): Rasterio reference profile for writing output \"\"\" # Import damage state dr2ds = pd . read_csv ( 'csv/ratio_to_damage.csv' ) dr2ds . columns = [ 'DS' , 'DS_level ' , 'cdv ' , 'dr_range' , 'dr_lwr' , 'dr_upr' ] # Get the damage ratio f_damageRatio = lambda mn , dsp , load : scipy . stats . norm ( loc = math . log ( mn ), scale = dsp ) . cdf ( np . log ( load )) haz_data [ haz_data < .1 ] = np . nan damageRatio = f_damageRatio ( vuln [ 'load_mean' ], vuln [ 'load_disp' ], haz_data ) # Multiply the total by the damage ratio and by the number of buildings that were exposed to a specific tephra fall load loss = damageRatio * vuln [ 'tot_rep_cost' ] * build_data loss [ loss < 0 ] = 0 # Just make sure there are no negative values # Convert damage ratio to damage state damageState = np . zeros ( damageRatio . shape ) for i in range ( 1 , 6 ): damageState [ damageRatio >= dr2ds . iloc [ i ][ 'dr_upr' ]] = i ## Write the rasters if flName is not None : # Write damage ratio as raster with rio . open ( os . path . join ( outPath , erup , '_exposure/damageRatio_ {} ' . format ( flName )), 'w' , ** profile ) as dst : dst . write ( damageRatio , 1 ) # Write loss as raster with rio . open ( os . path . join ( outPath , erup , '_exposure/loss_ {} ' . format ( flName )), 'w' , ** profile ) as dst : dst . write ( loss , 1 ) ## Write the tiffs # Damage ratio table damageRatioR = np . round ( damageRatio , 1 ) DR = np . round ( np . linspace ( 0 , 1 , 11 ), 2 ) storDR = { 'damageRatio' : DR , 'nBuildings' : np . zeros ( DR . shape ), 'loss' : np . zeros ( DR . shape ), } storDR = pd . DataFrame ( storDR ) storDR = storDR . set_index ( 'damageRatio' ) for iR in DR : idx = damageRatioR == iR storDR . loc [ iR , 'nBuildings' ] = np . sum ( build_data [ idx ]) storDR . loc [ iR , 'loss' ] = np . sum ( loss [ idx ]) # Damage state table DS = np . linspace ( 0 , 5 , 6 ) # DS = [int(d) for d in DS] storDS = { 'damageState' : DS , 'nBuildings' : np . zeros ( DS . shape ), 'loss' : np . zeros ( DS . shape ), } storDS = pd . DataFrame ( storDS ) storDS = storDS . set_index ( 'damageState' ) for iR in DS : idx = damageState == iR storDS . loc [ iR , 'nBuildings' ] = np . sum ( build_data [ idx ]) storDS . loc [ iR , 'loss' ] = np . sum ( loss [ idx ]) return storDR , storDS","title":"getBuildingImpact()"},{"location":"volcGIS_exposureAnalysis/#volcgis.exposureAnalysis.getExposure","text":"Compute exposure from masking exposure datasets with hazard data. For the landcover data, using CGLS so urban==50 and crops==40 Parameters: Name Type Description Default haz_data np.array Hazard data required pop_data np.array Population density data required LC_data np.array Landcover data required res int Raster resolution required val float Hazard value to mask required Returns: Type Description tuple A tuple containing: population (float) : Cumulative number of people within hazard value crops (float) : Total exposed crop area (km^2) urban (float) : Total exposed urban area (km^2) Source code in volcgis/exposureAnalysis.py def getExposure ( haz_data , pop_data , LC_data , res , val ): \"\"\" Compute exposure from masking exposure datasets with hazard data. For the landcover data, using `CGLS` so `urban==50` and `crops==40` Args: haz_data (np.array): Hazard data pop_data (np.array): Population density data LC_data (np.array): Landcover data res (int): Raster resolution val (float): Hazard value to mask Returns: tuple: A tuple containing: - `population (float)`: Cumulative number of people within hazard value - `crops (float)`: Total exposed crop area (km^2) - `urban (float)`: Total exposed urban area (km^2) \"\"\" # Get hazard index idx = haz_data >= val # Population popTmp = np . sum ( pop_data [ idx ]) # Landcover / crops km2 idx = ( haz_data >= val ) & ( LC_data == 40 ) cropsTmp = np . sum ( idx ) * res ** 2 / 1e6 # Landcover / urban km2 idx = ( haz_data >= val ) & ( LC_data == 50 ) urbanTmp = np . sum ( idx ) * res ** 2 / 1e6 return round ( popTmp , 0 ), round ( cropsTmp , 0 ), round ( urbanTmp , 0 )","title":"getExposure()"},{"location":"volcGIS_exposureAnalysis/#volcgis.exposureAnalysis.getFeatures","text":"Function to parse features from GeoDataFrame in such a manner that rasterio wants them Source code in volcgis/exposureAnalysis.py def getFeatures ( gdf ): \"\"\"Function to parse features from GeoDataFrame in such a manner that rasterio wants them\"\"\" return [ json . loads ( gdf . to_json ())[ 'features' ][ 0 ][ 'geometry' ]]","title":"getFeatures()"},{"location":"volcGIS_exposureAnalysis/#volcgis.exposureAnalysis.getRNDS","text":"Parameters: Name Type Description Default hazardPath str Path to hazard file required dictMap dict required road gpd required epsg int Digits of the epsg code required intensity bool Defines if hazard file contains probabilities (False) or hazard intensity metrics (True) required Returns: Type Description tuple A tuple containing: - rnds (float, dict): RNDN value, either as a float (if intensity==True) or a dictionary (if intensity==False) - roadLength (pd.DataFrame): Length of each road type defined in the `highway` column of the road variable. Each row is a road type, each column is a single value defined in dictMap - rsds (pd.DataFrame): RSDS value of each road segment defined by `Road_ID` Source code in volcgis/exposureAnalysis.py def getRNDS ( hazardPath , dictMap , road , epsg , intensity ): \"\"\" Arguments: hazardPath (str): Path to hazard file dictMap (dict): road (gpd): epsg (int): Digits of the epsg code intensity (bool): Defines if hazard file contains probabilities (False) or hazard intensity metrics (True) Returns: tuple: A tuple containing: - rnds (float, dict): RNDN value, either as a float (if intensity==True) or a dictionary (if intensity==False) - roadLength (pd.DataFrame): Length of each road type defined in the `highway` column of the road variable. Each row is a road type, each column is a single value defined in dictMap - rsds (pd.DataFrame): RSDS value of each road segment defined by `Road_ID` \"\"\" # Make sure dicMap is ordered in decreasing keys dictMap = dict ( sorted ( dictMap . items (), key = lambda item : item [ 0 ], reverse = True )) # Convert it to a tuple so we can iterate back and forth inpVal = [( k , v ) for k , v in dictMap . items ()] # Output rnds = {} # Set id road = road . set_index ( 'Road_ID' ) # Output dataframe that will contain the length roadLength = pd . DataFrame ( columns = dictMap . keys (), index = road . highway . unique ()) with rio . open ( hazardPath ) as src : #Read image image = src . read () # Loop through dictMap, which returns threshold and impact score # for threshold, score in dictMap.items(): for i in range ( 0 , len ( inpVal )): # Get threshold and score threshold = inpVal [ i ][ 0 ] #threshold_str = str(threshold) score = inpVal [ i ][ 1 ] # Create a mask mask = image >= threshold mask = mask . astype ( 'uint8' ) # In case the hazard type is tephra and the loop is not pointing to the innermost zone, # then we substract the previous mask if i > 0 and intensity : maskP = image >= inpVal [ i - 1 ][ 0 ] maskP = maskP . astype ( 'uint8' ) mask = mask - maskP shapes = rio . features . shapes ( mask , transform = src . transform ) # Extract geometry from shapes geometry = [] for shapedict , value in shapes : if value == 1 : geometry . append ( shape ( shapedict )) # Create gdf for clipping gdf = gpd . GeoDataFrame ( { 'geometry' : geometry }, crs = \"EPSG: {} \" . format ( epsg )) # In case the mask for the given threshold is empty if gdf . size == 0 : rnds [ threshold ] = 0 else : # Create GeoDataFrame clipped_road = gpd . clip ( road , gdf ) clipped_road [ 'impact_score' ] = score clipped_road [ 'RSDS_ {} ' . format ( threshold )] = clipped_road [ 'Criticality score' ] * clipped_road [ 'LoR_score' ] * clipped_road [ 'impact_score' ] rnds [ threshold ] = clipped_road [ 'RSDS_ {} ' . format ( threshold )] . sum () # Calculate total road length per `highway` type and append to the storage df roadLengthTmp = clipped_road . groupby ( 'highway' ) . sum ()[[ 'Length_m' ]] roadLength . loc [ roadLengthTmp . index , threshold ] = roadLengthTmp . loc [ roadLengthTmp . index , 'Length_m' ] # Append the RSDS to the full road network road = road . join ( clipped_road [[ 'RSDS_ {} ' . format ( threshold )]]) # Sum all values if intensity == True : rnds = sum ( rnds . values ()) else : pass # Remove the highway types that don't have any data roadLength = roadLength . dropna ( how = 'all' ) # Filter the RSDS columns to save them with the `Road_ID` rsds = road . filter ( regex = ( \"RSDS*\" )) rsds = rsds . dropna ( how = 'all' ) return rnds , roadLength , rsds","title":"getRNDS()"},{"location":"volcGIS_exposureAnalysis/#volcgis.exposureAnalysis.updateBuildingExposure","text":"Update building exposure and impact to tephra accumulation Parameters: Name Type Description Default damageRatio pd.DataFrame Master damage ratio dataframe required damageState pd.DataFrame Master damage state dataframe required volcano str Volcano name required VEI str VEI required prob str Probability required typ str Building type required DR pd.DataFrame Damage ratio dataframe for a given volcano/vei/prob required DS pd.DataFrame Damage state dataframe for a given volcano/vei/prob required Source code in volcgis/exposureAnalysis.py def updateBuildingExposure ( damageRatio , damageState , volcano , VEI , prob , typ , DR , DS ): \"\"\" Update building exposure and impact to tephra accumulation Arguments: damageRatio (pd.DataFrame): Master damage ratio dataframe damageState (pd.DataFrame): Master damage state dataframe volcano (str): Volcano name VEI (str): VEI prob (str): Probability typ (str): Building type DR (pd.DataFrame): Damage ratio dataframe for a given volcano/vei/prob DS (pd.DataFrame): Damage state dataframe for a given volcano/vei/prob \"\"\" DR [ 'volcano' ] = volcano DR [ 'VEI' ] = VEI DR [ 'prob' ] = prob DR [ 'type' ] = typ DS [ 'volcano' ] = volcano DS [ 'VEI' ] = VEI DS [ 'prob' ] = prob DS [ 'type' ] = typ return damageRatio . append ( DR ), damageState . append ( DS )","title":"updateBuildingExposure()"},{"location":"volcGIS_exposureAnalysis/#volcgis.exposureAnalysis.updateExposure","text":"Updates main exposure dataframe. Buildings loss is in millions. Parameters: Name Type Description Default EXPOSURE pd.DataFrame Main dataframe to update required volcano str Volcano name required hazard str Hazard name required VEI float VEI required prob float Probability required intensity float Hazard intensity required buffer float required volume float required pop float required crops float required urban float required RNDS float required buildingsLoss float required Returns: Type Description pd.DataFrame Updated data frame Source code in volcgis/exposureAnalysis.py def updateExposure ( EXPOSURE , volcano , hazard , VEI , prob , intensity , buffer , volume , pop , crops , urban , RNDS , buildingsLoss ): \"\"\" Updates main exposure dataframe. Buildings loss is in millions. Args: EXPOSURE (pd.DataFrame): Main dataframe to update volcano (str): Volcano name hazard (str): Hazard name VEI (float): VEI prob (float): Probability intensity (float): Hazard intensity buffer (float): volume (float): pop (float): crops (float): urban (float): RNDS (float): buildingsLoss (float): Returns: pd.DataFrame: Updated data frame \"\"\" expTmp = { 'volcano' : [ volcano ], 'hazard' : [ hazard ], 'VEI' : [ VEI ], 'prob' : [ prob ], 'mass' : [ intensity ], 'buffer' : [ buffer ], 'volume' : [ volume ], 'pop_count' : [ pop ], 'area_crops' : [ crops ], 'area_urban' : [ urban ], 'RNDS' : [ RNDS ], 'buildingsLoss' :[ buildingsLoss ], } expTmp = pd . DataFrame ( expTmp ) # If roadLength is defined, then add the columns with length_ appended to the column name # if roadLength is not None: # for iRoad in range(roadLength.shape[0]): # name = roadLength.iloc[iRoad].name # expTmp['length_' + name] = roadLength.loc[name].values[0] return EXPOSURE . append ( expTmp )","title":"updateExposure()"},{"location":"volcGIS_exposureAnalysis/#volcgis.exposureAnalysis.updateRoadExposure","text":"Updates road exposure. Length is in km Source code in volcgis/exposureAnalysis.py def updateRoadExposure ( roadExposure , volcano , hazard , VEI , prob , intensity , buffer , volume , roadLength ): \"\"\" Updates road exposure. Length is in km \"\"\" expTmp = { 'volcano' : [ volcano ], 'hazard' : [ hazard ], 'VEI' : [ VEI ], 'prob' : [ prob ], 'mass' : [ intensity ], 'buffer' : [ buffer ], 'volume' : [ volume ], } expTmp = pd . DataFrame ( expTmp ) for iRoad in range ( roadLength . shape [ 0 ]): name = roadLength . iloc [ iRoad ] . name expTmp [ 'length_' + name ] = round ( roadLength . loc [ name ] . values [ 0 ] / 1e3 , 2 ) return roadExposure . append ( expTmp )","title":"updateRoadExposure()"},{"location":"volcGIS_exposureAnalysis/#volcgis.exposureAnalysis.updateRSDS","text":"Update the rsds for a given eruption. It assumes that all the variables (i.e. hazard type, VEI, probs etc) are contained in the column name. Just thinking along mapping them on a GIS, it will make more sense to have all the data in one single file so only one join is required. Parameters: Name Type Description Default RSDS pd.DataFrame Main storage, row is Road_ID , column is a given hazard occurrence required rsds pd.DataFrame RSDS for one hazard occurrence, row is Road_ID required Returns: Type Description pd.DataFrame Updated RSDS dataframe Source code in volcgis/exposureAnalysis.py def updateRSDS ( RSDS , rsds ): \"\"\" Update the rsds for a given eruption. It assumes that all the variables (i.e. hazard type, VEI, probs etc) are contained in the column name. Just thinking along mapping them on a GIS, it will make more sense to have all the data in one single file so only one join is required. Args: RSDS (pd.DataFrame): Main storage, row is `Road_ID`, column is a given hazard occurrence rsds (pd.DataFrame): RSDS for one hazard occurrence, row is `Road_ID` Returns: pd.DataFrame: Updated RSDS dataframe \"\"\" rsds_tmp = rsds . copy () # If first call of updateRSDS if RSDS . shape [ 0 ] == 0 : RSDS = rsds_tmp else : RSDS = RSDS . join ( rsds_tmp ) return RSDS","title":"updateRSDS()"}]}